{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure2(Stackedbar) for bertopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "p = os.path.abspath('../..')\n",
    "sys.path.insert(1, p)\n",
    "\n",
    "# pp = os.path.abspath('../../../visualization')\n",
    "# sys.path.insert(1, pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gc import collect\n",
    "\n",
    "import pickle\n",
    "import lib.stats.stats as st\n",
    "from utils.statistics import *\n",
    "from utils.settings import set_matplotlib\n",
    "from utils.distribution_collector import (collect_topic_distributions,\n",
    "                                get_top_and_bottom_topics,\n",
    "                                extract_specific_topics)\n",
    "from constants import CONSTANTS\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "import matplotlib as mpl\n",
    "\n",
    "import psycopg2\n",
    "# from utils.statistics import *\n",
    "import config.config as conf\n",
    "import datetime\n",
    "import re\n",
    "# 포뮬러 구성\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import font_manager\n",
    "import matplotlib as mpl\n",
    "from matplotlib import font_manager as fm\n",
    "\n",
    "# 설치된 폰트 이름과 경로 확인\n",
    "for font in font_manager.fontManager.ttflist:\n",
    "    if 'Helvetica' in font.name: # 'Nanum' 대신 원하는 글꼴의 일부를 입력하여 검색할 수 있습니다.\n",
    "        print(font.name, font.fname)\n",
    "\n",
    "# 직접 경로로 Helvetica 폰트 불러오기\n",
    "font_path = \"/System/Library/Fonts/Helvetica.ttc\"\n",
    "font_prop = fm.FontProperties(fname=font_path)\n",
    "font_name = font_prop.get_name()\n",
    "print(f\"Registered font name: {font_name}\")\n",
    "\n",
    "mpl.rcParams['font.family'] = font_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f'../../../so_pjt_src/{CONSTANTS.bert_monthly_data_dir_3[3:]}'\n",
    "output_dir = './fig/'\n",
    "date_range = 'Weekly'\n",
    "model = 'BERT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = os.listdir(data_dir)\n",
    "df = pd.DataFrame()\n",
    "# 디렉토리 내의 파일을 for 문으로 반복\n",
    "for i in lst:\n",
    "\tjs = load_json(f'{data_dir}/{i}')\n",
    "\ttmp = pd.DataFrame(js)\n",
    "\ttmp['json'] = i\n",
    "\tdf = pd.concat([df, tmp], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['id', 'creationdate', 'Topic', 'json']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['creationdate'] = pd.to_datetime(df['creationdate'], format=\"mixed\")\n",
    "df['cdate'] = pd.to_datetime(df['creationdate'], format=\"%Y-%m-%d\").dt.date\n",
    "df['cdate'] = pd.to_datetime(df['cdate'], format=\"%Y-%m-%d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_list = list(df[(df['cdate']>=CONSTANTS.start_date_snap1)&\\\n",
    "                 (df['cdate']<CONSTANTS.end_date_snap1)]\\\n",
    "                .groupby('Topic').count()['id'].reset_index().sort_values(by = 'id', ascending=False)['Topic'])\n",
    "\n",
    "\n",
    "top10list = topic_list[:10]\n",
    "bot10list = topic_list[-10:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snap1_df = df[df['cdate'] <  CONSTANTS.end_date_snap1]\n",
    "snap2_df = df[df['cdate'] >= CONSTANTS.start_date_snap2]\n",
    "tot_df   = df[(df['cdate']>= CONSTANTS.start_date_snap1) & (df['cdate']< CONSTANTS.end_date_snap2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snap1_df['rel_week'] = np.floor((snap1_df['cdate']-\\\n",
    "                       CONSTANTS.std_date_snap1).dt.days/7) \n",
    "snap2_df['rel_week'] = np.floor((snap2_df['cdate']-\\\n",
    "                       CONSTANTS.std_date_snap2).dt.days/7) \n",
    "tot_df['rel_week'] = np.floor((tot_df['cdate']-\\\n",
    "                       CONSTANTS.std_date_snap1).dt.days/7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proportion_calc(df):\n",
    "    df_tot = df.groupby('rel_week').count()['id'].reset_index(name = 'tot_cnt')\n",
    "    df_topic = df.groupby(['rel_week', 'Topic']).count()['id'].reset_index(name = 'cnt')\n",
    "    df_topic_r = pd.merge(df_topic, df_tot, on = 'rel_week')\n",
    "    df_topic_r['pct'] = df_topic_r['cnt']/df_topic_r['tot_cnt']\n",
    "\n",
    "    df_topic_r_t = df_topic_r[df_topic_r['Topic'].isin(top10list)]\n",
    "    df_topic_r_b = df_topic_r[df_topic_r['Topic'].isin(bot10list)]\n",
    "\n",
    "    proportion_dict = {'Top 20% Topics' : df_topic_r_t, 'Bottom 20% Topics' : df_topic_r_b}\n",
    "    list_10 = {'Top 20% Topics' : top10list, 'Bottom 20% Topics' : bot10list}\n",
    "    return proportion_dict, list_10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snap1_dict, list_= proportion_calc(snap1_df)\n",
    "snap2_dict, list_= proportion_calc(snap2_df)\n",
    "tot_dict,   list_= proportion_calc(tot_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "color_list = [[ \n",
    "   \"#4575b4\",  # deep blue\n",
    "    \"#91bfdb\",  # light blue\n",
    "    \"#e0f3f8\",  # pale blue\n",
    "    \"#a6d96a\",  # light green\n",
    "    \"#1a9850\",  # green\n",
    "    \"#d9ef8b\",  # lime yellow\n",
    "    \"#fee08b\",  # beige\n",
    "    \"#fdae61\",  # soft orange\n",
    "    \"#f46d43\",  # coral orange\n",
    "    \"#d73027\"   # muted red\n",
    "    ],\n",
    "   [\n",
    "    \"#8c510a\",  # dark brown\n",
    "    \"#bf812d\",  # brown-gold\n",
    "    \"#dfc27d\",  # sand yellow\n",
    "    \"#f6e8c3\",  # beige\n",
    "    \"#c7eae5\",  # light aqua\n",
    "    \"#80cdc1\",  # teal\n",
    "    \"#35978f\",  # muted teal\n",
    "    \"#01665e\",  # deep green\n",
    "    \"#003c30\",  # near-black green\n",
    "    \"#f5f5f5\"   # pale gray (neutral base)\n",
    "]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### create a figure with multiple subplots\n",
    "sharey = True ## 또는 sharey=False\n",
    "sharex = True ## 또는 sharex=False\n",
    "# g_num  = len(proportion_dict.items())\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize = (18, 6), constrained_layout=True)\n",
    "colors = plt.get_cmap('tab20').colors \n",
    "\n",
    "\n",
    "for x, (title, proportion) in enumerate(tot_dict.items()):\n",
    "    rel_week = sorted(proportion['rel_week'].unique())  # 주차 순서 보장\n",
    "    topic_list = list(proportion['Topic'].unique())\n",
    "    order_list = list_[title]\n",
    "    colors = color_list[x]\n",
    "\n",
    "    # 전체 주차 길이에 맞춰 bottom 초기화\n",
    "    bottom = np.zeros(len(rel_week))\n",
    "    \n",
    "\n",
    "    for idx, topic in enumerate(order_list):\n",
    "        # topic별 데이터\n",
    "        t_p = proportion[proportion['Topic'] == topic]\n",
    "\n",
    "        # topic별 주차별 비율을 rel_week 길이에 맞춰 채우기\n",
    "        count_full = np.zeros(len(rel_week))\n",
    "        for i, rw in enumerate(t_p['rel_week']):\n",
    "            if rw in rel_week:\n",
    "                rw_idx = rel_week.index(rw)\n",
    "                count_full[rw_idx] = t_p.loc[t_p['rel_week'] == rw, 'pct'].values[0]\n",
    "\n",
    "        # bar plot\n",
    "        axs[x].bar(rel_week, count_full, bottom=bottom, label=topic, color=colors[idx], width=1.0, align='center')\n",
    "\n",
    "        bottom += count_full  # 누적\n",
    "\n",
    "    # 보조선 및 제목/레이블 등\n",
    "    axs[x].axvline(x=0, color='tab:red', linestyle='-.', linewidth=1)\n",
    "    axs[x].set_title(f'{title}', fontsize=25)\n",
    "    axs[x].tick_params(axis='x', labelsize=16)\n",
    "    axs[x].tick_params(axis='y', labelsize=16)\n",
    "\n",
    "axs[0].set_ylabel(\"Accumulated topic share\", fontsize = 22)\n",
    "\n",
    "\n",
    "fig.supxlabel(\"Week relative to ChatGPT release\", fontsize=22) \n",
    "\n",
    "plt.savefig(f\"{output_dir}C_Result_Fig2_2.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '2021-12-29 00:00:00', '2022-01-05 00:00:00'\n",
    "df.loc[(df['cdate']>= '2021-12-01')&(df['cdate']<'2021-12-08'), 'json'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['json']== '10.json'), 'cdate'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 7\n",
    "top_and_bottom_topics = get_top_and_bottom_topics(data_dir)\n",
    "weekly_topic_distributions = collect_topic_distributions(window=window,\n",
    "                                                            data_dir=data_dir, weekday_list = None, options=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"weekly_topic_distributions.pkl\",\"wb\") as f:\n",
    "    pickle.dump(weekly_topic_distributions, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"weekly_topic_distributions.pkl\",\"rb\") as f:\n",
    "    weekly_topic_distributions = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ginis = list(map(lambda x: calculate_gini(list(x.values())), weekly_topic_distributions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropies = list(map(lambda x: calculate_entropy(list(x.values())), weekly_topic_distributions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini_entropy_dict = {'Gini Coefficient' : ginis, 'Entropy' : entropies}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(weekly_topic_distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_week = np.array(np.arange(-52, 52))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_0 = st.Stats(rel_week, entropies[:104], 2, 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_stat_0, p_value_0 = st_0.chow_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### create a figure with multiple subplots\n",
    "sharey = True ## 또는 sharey=False\n",
    "sharex = True ## 또는 sharex=False\n",
    "# g_num  = len(proportion_dict.items())\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize = (24, 6), constrained_layout=True)\n",
    "colors = plt.get_cmap('tab20').colors \n",
    "\n",
    "\n",
    "for x, (title, proportion) in enumerate(tot_dict.items()):\n",
    "    rel_week = sorted(proportion['rel_week'].unique())\n",
    "    topic_list = list(proportion['Topic'].unique())\n",
    "    order_list = top_and_bottom_topics[x]\n",
    "    colors = color_list[x]\n",
    "\n",
    "    # 전체 주차 길이에 맞춰 bottom 초기화\n",
    "    bottom = np.zeros(len(rel_week))\n",
    "\n",
    "    for idx, topic in enumerate(order_list):\n",
    "        # topic별 데이터\n",
    "        t_p = proportion[proportion['Topic'] == topic]\n",
    "\n",
    "        # topic별 주차별 비율을 rel_week 길이에 맞춰 채우기\n",
    "        count_full = np.zeros(len(rel_week))\n",
    "        for i, rw in enumerate(t_p['rel_week']):\n",
    "            if rw in rel_week:\n",
    "                rw_idx = rel_week.index(rw)\n",
    "                count_full[rw_idx] = t_p.loc[t_p['rel_week'] == rw, 'pct'].values[0]\n",
    "\n",
    "        # bar plot\n",
    "        axs[x].bar(rel_week, count_full, bottom=bottom, label=topic, color=colors[idx], width=1.0, align='center')\n",
    "        bottom += count_full  # 누적\n",
    "\n",
    "    # 보조선 및 제목/레이블 등\n",
    "    axs[x].axvline(x=0, color='tab:red', linestyle='-.', linewidth=1)\n",
    "    # axs[x].set_title(f'{title}', fontsize=25)\n",
    "\n",
    "    axs[x].text(0.5, 1.05, f\"{title}\",\n",
    "            ha='center', va='bottom', fontsize=22, fontweight='bold', transform=axs[x].transAxes)\n",
    "\n",
    "    axs[x].text(0.5, 1.00, \"\",\n",
    "        ha='center', va='bottom', fontsize=15, transform=axs[x].transAxes)  \n",
    "\n",
    "    axs[x].tick_params(axis='x', labelsize=16)\n",
    "    axs[x].tick_params(axis='y', labelsize=16)\n",
    "\n",
    "# for idx, measure in enumerate(gini_entropy_dict.keys()):\n",
    "#     idx+=2\n",
    "# entropy만 시각화\n",
    "idx = 2\n",
    "list_ = gini_entropy_dict['Entropy'][:104]\n",
    "x_rel, divider = get_dist_x_div(list_)\n",
    "\n",
    "reg_bf = calc_regression_with_ci(x_rel[:divider], list_[:divider])\n",
    "reg_af = calc_regression_with_ci(x_rel[divider:], list_[divider:])\n",
    "\n",
    "reg_bf_summary = reg_bf[\"pred_summary\"]\n",
    "reg_af_summary = reg_af[\"pred_summary\"]\n",
    "\n",
    "# 회귀선 (예측값)\n",
    "reg_bf_y_pred = reg_bf_summary[\"mean\"]\n",
    "reg_af_y_pred = reg_af_summary[\"mean\"]\n",
    "# 신뢰구간\n",
    "reg_bf_ci_lower = reg_bf_summary[\"mean_ci_lower\"]\n",
    "reg_bf_ci_upper = reg_bf_summary[\"mean_ci_upper\"]\n",
    "\n",
    "reg_af_ci_lower = reg_af_summary[\"mean_ci_lower\"]\n",
    "reg_af_ci_upper = reg_af_summary[\"mean_ci_upper\"]\n",
    "\n",
    "p_value_txt = '($p < 0.001$)' if p_value_0 <0.001 else f'($p = {p_value_0:.3f}$)'\n",
    "\n",
    "axs[idx].scatter(x_rel, list_, color = 'darkgray', alpha = 0.7,  s=10, marker='x')\n",
    "axs[idx].axvline(x=0, color='tab:red', linestyle='-.', linewidth=1)\n",
    "# axs[idx].set_ylabel(f\"{measure} of Topic Distribution\", fontsize = 10)\n",
    "axs[idx].plot(x_rel[:divider], reg_bf_y_pred, linewidth=2, label = 'before ChatGPT')\n",
    "axs[idx].plot(x_rel[divider:], reg_af_y_pred, linewidth=2, label = 'after ChatGPT')\n",
    "\n",
    "axs[idx].fill_between(x_rel[:divider], reg_bf_ci_lower, reg_bf_ci_upper, alpha=0.1)\n",
    "axs[idx].fill_between(x_rel[divider:], reg_af_ci_lower, reg_af_ci_upper, alpha=0.1)\n",
    "\n",
    "axs[idx].legend(frameon=False, loc='best', fontsize=14)\n",
    "# axs[idx].set_title(f\"Changes in Entropy (topic){p_value_txt}\", fontsize=25)\n",
    "# axs[idx].grid(True, linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "\n",
    "axs[idx].tick_params(axis='x', labelsize=16)\n",
    "axs[idx].tick_params(axis='y', labelsize=16)\n",
    "\n",
    "\n",
    "axs[idx].text(0.5, 1.05, f\"Changes in Entropy (topic)\",\n",
    "            ha='center', va='bottom', fontsize=22, fontweight='bold', transform=axs[idx].transAxes)\n",
    "\n",
    "axs[idx].text(0.5, 1.00, f\"{p_value_txt}\",\n",
    "        ha='center', va='bottom', fontsize=15, transform=axs[idx].transAxes)  \n",
    "\n",
    "# for idx, measure in enumerate(gini_entropy_dict.keys()):\n",
    "#     idx+=2\n",
    "# entropy만 시각화\n",
    "idx = 3\n",
    "list_ = gini_entropy_dict['Entropy'][52:]\n",
    "x_rel, divider = get_dist_x_div(list_)\n",
    "\n",
    "reg_bf = calc_regression_with_ci(x_rel[:divider], list_[:divider])\n",
    "reg_af = calc_regression_with_ci(x_rel[divider:], list_[divider:])\n",
    "\n",
    "reg_bf_summary = reg_bf[\"pred_summary\"]\n",
    "reg_af_summary = reg_af[\"pred_summary\"]\n",
    "\n",
    "# 회귀선 (예측값)\n",
    "reg_bf_y_pred = reg_bf_summary[\"mean\"]\n",
    "reg_af_y_pred = reg_af_summary[\"mean\"]\n",
    "# 신뢰구간\n",
    "reg_bf_ci_lower = reg_bf_summary[\"mean_ci_lower\"]\n",
    "reg_bf_ci_upper = reg_bf_summary[\"mean_ci_upper\"]\n",
    "\n",
    "reg_af_ci_lower = reg_af_summary[\"mean_ci_lower\"]\n",
    "reg_af_ci_upper = reg_af_summary[\"mean_ci_upper\"]\n",
    "\n",
    "p_value_txt = '($p < 0.001$)' if p_value_0 <0.001 else f'($p = {p_value_0:.3f}$)'\n",
    "\n",
    "axs[idx].scatter(x_rel, list_, color = 'darkgray', alpha = 0.7,  s=10, marker='x')\n",
    "axs[idx].axvline(x=0, color='tab:red', linestyle='-.', linewidth=1)\n",
    "# axs[idx].set_ylabel(f\"{measure} of Topic Distribution\", fontsize = 10)\n",
    "axs[idx].plot(x_rel[:divider], reg_bf_y_pred, linewidth=2, label = 'before ChatGPT')\n",
    "axs[idx].plot(x_rel[divider:], reg_af_y_pred, linewidth=2, label = 'after ChatGPT')\n",
    "\n",
    "axs[idx].fill_between(x_rel[:divider], reg_bf_ci_lower, reg_bf_ci_upper, alpha=0.1)\n",
    "axs[idx].fill_between(x_rel[divider:], reg_af_ci_lower, reg_af_ci_upper, alpha=0.1)\n",
    "\n",
    "axs[idx].legend(frameon=False, loc='best', fontsize=14)\n",
    "# axs[idx].set_title(f\"Changes in Entropy (topic){p_value_txt}\", fontsize=25)\n",
    "# axs[idx].grid(True, linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "\n",
    "axs[idx].tick_params(axis='x', labelsize=16)\n",
    "axs[idx].tick_params(axis='y', labelsize=16)\n",
    "\n",
    "\n",
    "axs[idx].text(0.5, 1.05, f\"Changes in Entropy (topic)\",\n",
    "            ha='center', va='bottom', fontsize=22, fontweight='bold', transform=axs[idx].transAxes)\n",
    "\n",
    "axs[idx].text(0.5, 1.00, f\"{p_value_txt}\",\n",
    "        ha='center', va='bottom', fontsize=15, transform=axs[idx].transAxes)  \n",
    "\n",
    "axs[0].set_ylabel(\"Accumulated topic share\", fontsize = 22)\n",
    "axs[2].set_ylabel(f\"Entropy\", fontsize = 22)\n",
    "\n",
    "fig.supxlabel(\"Weeks relative to ChatGPT release\", fontsize=22) \n",
    "plt.savefig(f\"{output_dir}C_Result_Fig2_1.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
